## บทเรียนที่คุ้มค่า

จากการเดินทางทั้งหมด เราได้บทเรียนสำคัญหลายข้อที่คุ้มค่ากับเวลาและความพยายามที่ลงไป

**บทเรียนแรก** คือ LLM หรือ Large Language Model ไม่ใช่ระบบที่ deterministic หรือให้ผลลัพธ์แน่นอนเสมอ เพราะมันมี temperature มากกว่าศูนย์ทำให้มี randomness กระบวนการ sampling ไม่เหมือนเดิมทุกครั้ง และ context window มีขนาดจำกัด ดังนั้น consistency ที่ 95 ถึง 100% ถือว่าดีมากแล้ว การคาดหวัง 100% ตลอดเวลาเป็นเป้าหมายที่ไม่สมจริง

**บทเรียนที่สอง** คือหลักการ Garbage In Garbage Out ถ้าคำถามคลุมเครือ AI ก็ไม่รู้ว่าต้องตอบอะไร แต่ถ้าคำถามชัดเจนมีโครงสร้าง AI ก็ตอบได้ดี ตัวอย่างเช่น คำถามว่า "คะแนนสูง 80%" ไม่บอกว่าคะแนนแบบไหน AI จึงเลือกเอง แต่ถ้าถามว่า "Performance Rating ตาม Section 1.1 มากกว่าหรือเท่ากับ 4.0 จาก 5.0" AI ก็เข้าใจตรง

**บทเรียนที่สาม** คือ RAG หรือ Retrieval Augmented Generation ต้องการ good prompting เพื่อให้ได้ผลดี RAG จะช่วยได้เมื่อ prompt ระบุชื่อไฟล์ section ที่ต้องการ และมี hint ช่วย search แต่ถ้า prompt คลุมเครือ AI ก็ search ผิด section หรือข้ามข้อมูลสำคัญไป

**บทเรียนที่สี่** คือ glossary คือกุญแจสำคัญของความสำเร็จ glossary ที่ดีต้องลด ambiguity มี clear sections มีตัวอย่างและ FAQ เมื่อมี glossary ที่ดี AI ตอบถูกขึ้น user ถามได้ง่ายขึ้น และ consistency สูงขึ้นตามมา

**บทเรียนสุดท้าย** คือ user training สำคัญพอๆ กับการพัฒนาระบบ เราไม่สามารถ train AI ได้โดยตรง แต่เรา train user ได้ ถ้า user รู้วิธีใช้ template รู้จักอ้างอิง section รู้จักใส่ hint ระบบก็จะทำงานได้ดี ไม่งั้นแม้ระบบจะดีแค่ไหน ถ้า user ใช้ไม่ถูกวิธี ผลลัพธ์ก็ไม่ดี